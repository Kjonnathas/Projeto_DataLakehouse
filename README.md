# 1. Descri√ß√£o do Projeto

Este projeto open-source implementa uma arquitetura de DataLakehouse utilizando cont√™ineres Docker para facilitar a integra√ß√£o, o armazenamento e a an√°lise de grandes volumes de dados em formato distribu√≠do. A solu√ß√£o permite centralizar dados de um banco de dados PostgreSQL (com a base Northwind carregada via script SQL) em um reposit√≥rio escal√°vel na nuvem, possibilitando consultas e visualiza√ß√µes r√°pidas para insights de neg√≥cios. Este pipeline de dados √© ideal para ambientes de big data e an√°lises avan√ßadas, integrando ferramentas modernas de forma eficiente e acess√≠vel. Confira o reposit√≥rio para mais detalhes sobre o c√≥digo e configura√ß√µes.

# 2. Objetivo do Projeto

O ojetivo deste projeto √© colocar em pr√°tica os conhecimentos adquiridos no curso de Machine Learning e IA em ambientes distribu√≠dos da Data Science Academy (DSA). Ele serve como uma solu√ß√£o totalmente open-source para que usu√°rios de dados possam implementar uma arquitetura robusta e distribu√≠da para processar e analisar grandes conjuntos de dados.

# 3. Arquitetura do Projeto

![Arquitetura do Projeto DataLakehouse](images/Arquitetura_projeto.png)

# 4. Tecnologias Utilizadas

- Git
- SQL
- PostgresSQL
- Airbyte
- Amazon S3
- Dremio
- Docker

## 4.1 Descri√ß√£o de como as Tecnologias foram utilizadas

1. <strong> üêò PostgreSQL </strong>

   Utilizei o PostgreSQL como banco de dados transacional para armazenar e gerenciar os dados de origem do projeto. Foi tamb√©m a fonte de dados para o Airbyte, permitindo f√°cil acesso aos dados do banco Northwind, que foram carregados via script SQL para uso e an√°lise no pipeline.

2. <strong> üê≥ Docker Desktop </strong>

   O Docker Desktop foi a base para a cria√ß√£o dos cont√™ineres que rodaram todos os servi√ßos necess√°rios para a solu√ß√£o. Com ele, criei cont√™ineres para o PostgreSQL, Airbyte e Dremio, garantindo um ambiente controlado e eficiente para todos os processos de integra√ß√£o, armazenamento e an√°lise de dados.

3. <strong> ü™º Airbyte </strong>

   O Airbyte foi utilizado como ferramenta de integra√ß√£o de dados. Ele foi respons√°vel por conectar √† fonte de dados (neste caso, o PostgreSQL), onde os dados do banco Northwind foram carregados via script SQL. O Airbyte ent√£o carregava esses dados para o destino apropriado, mantendo-os atualizados e prontos para serem consumidos.

4. <strong> ‚òÅÔ∏è Amazon S3 </strong>

   Para o armazenamento dos dados, utilizei o Amazon S3 como DataLake, garantindo um reposit√≥rio centralizado, seguro e de alta disponibilidade na nuvem. O S3 foi escolhido devido √† sua escalabilidade, facilidade de integra√ß√£o e baixo custo, permitindo armazenar dados em qualquer formato (como Parquet, CSV, JSON) sem complica√ß√µes.

5. <strong> üõ†Ô∏è Dremio </strong>

   A pe√ßa chave para transformar esse projeto em um DataLakehouse foi o Dremio. O Dremio √© uma plataforma poderosa que permite consultar dados armazenados no DataLake diretamente atrav√©s de SQL, sem a necessidade de mover ou transformar fisicamente os dados. No meu projeto, os dados eram armazenados no S3 em formato Parquet, e o Dremio automaticamente reconhecia o formato dos arquivos, convertendo-os para tabelas relacionais, permitindo consultas r√°pidas e eficientes, al√©m de insights prontos para o neg√≥cio.

# 5. Exibi√ß√£o do Projeto

1. C√¥nteires do PostgreSQL, Airbyte e do Dremio em execu√ß√£o no Docker Desktop

<br>

![Docker Desktop](images/Docker.png)

<br>

2. Dados carregados no PostgreSQL via script SQL. O script foi extra√≠do do reposit√≥rio do GitHub chamado northwind_psql do autor pthom.

<br>

![Schema do Banco de Dados](images/Schema_db.png)

<br>

![Tabelas no Banco de Dados PostgreSQL](images/tabelas_postgres.png)

3. Configura√ß√µes de Source, Destination e Connection do Airbyte

<br>

![Tela de Source do Airbyte](images/Source_airbyte.png)

<br>

![Tela de Source do Airbyte](images/Source_config_airbyte.png)

<br>

![Tela de Source do Airbyte](images/Source_config_2_airbyte.png)

<br>

![Tela de Destination do Airbyte](images/Destination_airbyte.png)

<br>

![Tela de Destination do Airbyte](images/Destination_config_airbyte.png)

<br>

![Tela de Destination do Airbyte](images/Destination_config_2_airbyte.png)

<br>

![Tela de Connection do Airbyte](images/Connection_airbyte.png)

<br>

![Tela de Connection do Airbyte](images/Connection_config_airbyte.png)

<br>

![Tela de Connection do Airbyte](images/Connection_config_2_airbyte.png)

4. Bucket S3 criado e com os arquivos em parquet carregados atrav√©s da carga do Airbyte

<br>

![Tela da Amazon S3](images/Bucket_s3.png)

<br>

![Tela da Amazon S3](images/Bucket_s3_pasta_dados.png)

<br>

![Tela da Amazon S3](images/Bucket_s3_pasta_dados_schema_transacional_prod.png)

<br>

![Tela da Amazon S3](images/Bucket_s3_pasta_schema_transacional_prod.png)

<br>

![Tela da Amazon S3](images/Bucket_s3_pasta_todas_as_tabelas.png)

<br>

![Tela da Amazon S3](images/Bucket_s3_arquivo_carregado.png)

5. Processamento e An√°lise no Dremio

<br>

![Tela do Dremio](images/Dremio_source.png)

<br>

![Tela do Dremio](images/Dremio_source_arquivo.png)

<br>

![Tela do Dremio](images/Dremio_source_arquivo_config.png)

<br>

![Tela do Dremio](images/Dremio_source_tabelas.png)

<br>

![Tela do Dremio](images/Dremio_source_arquivo_tratado.png)

<br>

![Tela do Dremio](images/Dremio_resultado_final.png)

<br>

![Tela do Dremio](images/Dremio_resultado_query_1.png)

<br>

![Tela do Dremio](images/Dremio_resultado_query_2.png)

## An√°lise R√°pida de Resultado:

1. A categoria que mais vendeu foi a de Beverages com 9.532 produtos vendidos e somando um valor total de R$ 267.890,00. J√° a categoria que menos vendeu foi a de Grains/Cereals (Gr√£os e Cereais) com 4.562 itens vendidos e um valor de R$ 95.754,00, tendo uma diferen√ßa de R$ 172.136 entre ambos os produtos;

2. A categoria Beverages representa 21% do Faturamento Total, enquanto a de Grains/Cereals representa somente 8%;

3. O produto com maior valor vendido do cat√°logo foi o C√¥te de Blaye com 623 unidades vendidas e o um valor total de R$ 141.399. J√° o produto com menor valor vendido √© o Chocolade com apenas 138 unidades vendidas e um total de R$ 1.370;

4. Apesar do produto C√¥te de Blaye ter sido o produto com maior valor vendido, o produto mais vendido foi o Camembert Pierrot com 1.577 unidades vendidas, por√©m com somente 4% do valor total vendido entre todos os produtos. Para efeitos de compara√ß√£o, o produto C√¥te de Blaye tem 11% do total vendido.

# 6. Instala√ß√£o e Configura√ß√£o

- Pr√©-requisitos:

  1. Instalar o Docker Desktop;

     Link para download: https://www.docker.com/

  2. Instalar o PgAdmin (Client do PostgreSQL);

     Link para download: https://www.pgadmin.org/download/

  3. Instalar o Airbyte;

     Link para download: https://docs.airbyte.com/using-airbyte/getting-started/oss-quickstart

  4. Instalar o Git;

     Link para download: https://git-scm.com/downloads

  5. Criar uma conta na AWS;

     Link do site: https://aws.amazon.com/pt/console/

  6. Criar uma conta no Dremio;

     Link do site: https://www.dremio.com/get-started/

<br>

- Passo a passo:

1. Ap√≥s ter instalado os softwares informados e criado as contas, o primeiro passo √© criar os cont√™ineres no Docker. Abra o seu prompt de comando ou o terminal do Git e digite:

```

docker run --name <conteiner_name> -p 5432:5432 -e POSTGRES_DB=<db_name> -e POSTGRES_USER=<username> -e POSTGRES_PASSWORD=<password> -d postgres
```

1.1 Ap√≥s rodar este comando, o Docker criar√° o volume, a imagem e o cont√™iner do PostgreSQL.

1.2 Em seguida, abra o PgAdmin (se n√£o instalou ainda, precisar√° instalar agora). Ap√≥s abrir o PgAdmin, siga as seguintes etapas:

<br>

![Criando o Servidor no PostgreSQL](images/Postgres_criar_servidor.png)

<br>

![Criando o Servidor no PostgreSQL](images/Postgres_criar_servidor_2.png)

<br>

![Criando o Servidor no PostgreSQL](images/Postgres_criar_servidor_3.png)

<br>

![Criando o Servidor no PostgreSQL](images/Postgres_criar_servidor_4.png)

1.3 Ap√≥s criar o schema, clique com o bot√£o direito sobre o objeto
tables e selecione query tool. Em seguida ir√° abrir uma tela para criar c√≥digos em SQL. V√° at√© a pasta src/scripts e copie o c√≥digo em SQL e cole no query tool e depois aperte F5 ou clique no bot√£o de executar dispon√≠vel para que seja feita a cria√ß√£o das tabelas no seu schema;

1.4 Com as tabelas criadas, podemos prosseguir com a cria√ß√£o do cont√™iner do Airbyte. √â preciso fazer o download do arquivo dispon√≠vel no site do Airbyte atrav√©s do link disponibilizado. Feito o download, o arquivo ser√° baixado zipado. Fa√ßa a descompacta√ß√£o do arquivo. Basta clicar com o bot√£o direito e extrair tudo. Ap√≥s isso, ser√° necess√°rio criar uma vari√°vel de ambiente para o que o sistema operacional entenda o comando do airbyte. Entre na pasta do airbyte e copie o caminho. Em seguida, v√° at√© as vari√°veis de ambiente, clique no Path, editar e novo. Cole o caminho e depois clique em ok para salvar. Agora o sistema operacinal j√° deve reconhecer os comandos que vamos precisar digitar:

```
abctl version
```

Obs: Se o comando acima n√£o funcionar significa que algo de errado ao salvar a vari√°vel de ambiente ocorreu. Revise essa etapa! Se o prompt devolver a vers√£o √© porque funcionou normalmente e o sistema j√° identifica o comando.

1.5 Com o Docker Desktop aberto, digite o comando abaixo no seu prompt de comando:

```
abctl local install
```

Essa etapa costuma demorar pela primeira vez, ent√£o tenha paci√™ncia! √â importante verificar na documenta√ß√£o a exig√™ncia m√≠nima de hardware, pois o Airbyte √© pesado e consome bastante mem√≥ria. Se seu computador n√£o for muito bom, √© prov√°vel que v√° ter problemas com travamento.

1.6 Se tudo der certo e a instala√ß√£o concluir com sucesso, digite o comando:

```
abctl local credentials
```

O comando acima lhe dar√° um ID e uma senha, que ser√£o necess√°rios para logar no Airbyte via navegador. Teste a sua conex√£o indo at√© o navegador e acesse "localhost:8000", digite as credenciais e resolvido.

1.7 Depois que estiver funcionando, vamos precisar colocar o cont√™iner do Airbyte e do PostgreSQL na mesma rede para que eles possam se comunicar. Caso contr√°rio, ao tentar realizar a conex√£o da fonte de dados no Airbyte resultar√° em erro. Sendo assim, v√° ao prompt de comando e digite:

```
docker network inspect bridge
```

Este comando apresentar√° uma estrutura json e na chave Containers tanto o PostgreSQL quanto o Airbyte precisam aparecer. Acredito que por padr√£o o PostgreSQL j√° vai para a rede Bridge, mas no caso do Airbyte n√£o. Mas para evitar problemas voc√™ pode incluir o par√¢metro "--network bridge" ao criar o cont√™iner do PostgreSQL. Caso j√° tenha criado, basta excluir o cont√™iner no Docker Desktop e criar novamente com a inclus√£o deste par√¢metro. Em seguida, vamos incluir o cont√™iner do Airbyte na rede Bridge. Para isso, digite o seguinte comando:

```
docker network disconnect <rede_atual> <container_name>
```

Obs: Para saber em que rede o cont√™iner do Airbyte est√° digite: docker inspect -f '{{.NetworkSettings.Networks}}' container_name. Sabendo o nome da rede substitua no c√≥digo fornecido acima. Em seguida, continue com o comando:

```
docker network connect bridge <container_name>
```

O c√≥digo acima ir√° incluir o cont√™iner do Airbyte na rede Bridge e com isso os dois cont√™ineres estar√£o se comunicando.

1.8 Agora √© a parte de configurar o source, o destination e a connection no Airbyte. Visualizando as imagens disponibilizadas acima √© poss√≠vel fazer as configura√ß√µes da source sem grandes problemas. N√£o seguirei com o destination pois a Amazon faz cobran√ßa e n√£o quero que algo acabe n√£o saindo como o esperado e gere custos n√£o planejados. Isso quer dizer que, vou ficar devendo a parte da Amazon e do Dremio. Por√©m, h√° v√°rios tutoriais e v√≠deos gratuitos sobre o assunto. Caso queira muito seguir, procure por esse material e siga em frente!

<br>

## Licen√ßa

Este projeto est√° licenciado sob os termos da licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
